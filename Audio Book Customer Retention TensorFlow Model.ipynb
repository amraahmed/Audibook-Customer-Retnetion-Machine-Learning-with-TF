{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e08f4698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79bf5e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Amr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec7ab3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Reader():\n",
    "    def __init__(self,dataset,batch_size=None):\n",
    "        npz = np.load('Audiobooks_data_{0}tf.npz'.format(dataset))\n",
    "        self.inputs = npz['inputs'].astype(np.float32)\n",
    "        self.targets = npz['inputs'].astype(np.int64)\n",
    "        if batch_size is None:\n",
    "            self.batch_size = self.inputs.shape[0]\n",
    "        else:\n",
    "            self.batch_size = batch_size\n",
    "        self.curr_batch = 0\n",
    "        self.batch_count = self.inputs.shape[0] // self.batch_size\n",
    "    def __next__(self):\n",
    "        if self.curr_batch >= self.batch_count:\n",
    "            self.curr_batch = 0 \n",
    "            raise StopIteration\n",
    "        batch_slice = slice(self.curr_batch * self.batch_size,(self.curr_batch+1) * self.batch_size)\n",
    "        inputs_batch = self.inputs[batch_slice]\n",
    "        targets_batch = self.targets[batch_slice]\n",
    "        self.curr_batch +=1\n",
    "        \n",
    "        classes_num = 2\n",
    "        targets_one_hot = np.zeros((targets_batch.shape[0], classes_num))\n",
    "        targets_one_hot[range(targets_batch.shape[0]), targets_batch] = 1\n",
    "\n",
    "        return inputs_batch , targets_one_hot\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28fb78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "output_size = 2\n",
    "hidden_layer_size = 50\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "\n",
    "inputs = tf.placeholder(tf.float32,[None,input_size])\n",
    "targets = tf.placeholder(tf.float32,[None,output_size])\n",
    "\n",
    "\n",
    "w1 = tf.get_variable('weight1',[input_size,hidden_layer_size])\n",
    "b1 = tf.get_variable('b1',[hidden_layer_size])\n",
    "\n",
    "output1 = tf.nn.relu(tf.matmul(inputs,w1)+b1)\n",
    "\n",
    "\n",
    "w2 = tf.get_variable('weight2',[hidden_layer_size,hidden_layer_size])\n",
    "b2 = tf.get_variable('b2',[hidden_layer_size])\n",
    "\n",
    "output2 = tf.nn.relu(tf.matmul(output1,w2) + b2)\n",
    "\n",
    "w3 = tf.get_variable('weight3',[hidden_layer_size,output_size])\n",
    "b3 = tf.get_variable('b3',[output_size])\n",
    "\n",
    "outputs = tf.matmul(output2,w3)+b3\n",
    "\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=outputs,labels=targets)\n",
    "\n",
    "mean_loss = tf.reduce_mean(loss)\n",
    "\n",
    "optimize = tf.train.AdamOptimizer(learning_rate=.001).minimize(mean_loss)\n",
    "\n",
    "\n",
    "out_equal_target = tf.equal(tf.argmax(outputs,1),tf.argmax(targets,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(out_equal_target,tf.float32))\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "initializer = tf.global_variables_initializer()\n",
    "sess.run(initializer)\n",
    "batch_size = 100\n",
    "\n",
    "max_epochs = 15\n",
    "prev_val_loss = 9999999.\n",
    "\n",
    "\n",
    "train_data = Data_Reader('train', batch_size)\n",
    "validation_data = Data_Reader ('validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a37808",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_counter in range(max_epochs):\n",
    "    curr_epoch_loss = 0.\n",
    "    for input_batch, target_batch in train_data:\n",
    "        _,batch_loss = sess.run([optimize,mean_loss],\n",
    "                                feed_dict = {inputs:input_batch,targets:target_batch})\n",
    "        curr_epoch_loss = batch_loss\n",
    "        curr_epoch_loss /= train_data.batch_count\n",
    "    validation_loss = 0.\n",
    "    validation_accuracy = 0.\n",
    "    \n",
    "    for input_batch, target_batch in validation_data:\n",
    "        validation_loss,validation_accuracy = sess.run([mean_loss,accuracy],\n",
    "                                feed_dict = {inputs:input_batch,targets:target_batch})\n",
    "    print('Epochs'+str(epoch_counter+1)+'. Training loss: ' + '{0:3f}'.format(curr_epoch_loss)+'validation loss: ' +'{0:.3f}'.format(validation_loss)+'validation accuracy'+'{0.2f}'.format(validation_accuracy*100)+'%')\n",
    "    \n",
    "    \n",
    "    if validation_loss > prev_val_loss:\n",
    "        break\n",
    "    \n",
    "    prev_val_loss = validation_loss\n",
    "    \n",
    "    print(\"End of training\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "179b81c324ffca29e7398e9f8c090cd481bf40587cf953bddf9735e434759bbf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
